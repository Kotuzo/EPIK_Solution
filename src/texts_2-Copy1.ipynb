{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/ubuntu/Notebooks/Project/EPIK_Solution/all_data/extracted/transformed/'\n",
    "OCCURENCES_PATH = '/home/ubuntu/Notebooks/Project/EPIK_Solution/all_data/extracted/transformed/Occurrences/'\n",
    "SQ_DATA_PATH = '/home/ubuntu/Notebooks/Project/EPIK_Solution/all_data/extracted/search_queries/'\n",
    "AD_DATA_PATH = '/home/ubuntu/Notebooks/Project/EPIK_Solution/all_data/extracted/ads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 50)\n",
    "from learn.file_loader import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/ubuntu/Notebooks/Project/EPIK_Solution/all_data/extracted/data_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>predict_sold</th>\n",
       "      <th>predict_replies</th>\n",
       "      <th>predict_views</th>\n",
       "      <th>priceValue</th>\n",
       "      <th>derivative</th>\n",
       "      <th>average</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>private</th>\n",
       "      <th>exchange</th>\n",
       "      <th>free</th>\n",
       "      <th>price</th>\n",
       "      <th>new</th>\n",
       "      <th>full_description</th>\n",
       "      <th>period</th>\n",
       "      <th>description_len</th>\n",
       "      <th>full_description_len</th>\n",
       "      <th>paid_ads</th>\n",
       "      <th>nb_photos</th>\n",
       "      <th>photos_surface</th>\n",
       "      <th>title_contains_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1909313589</td>\n",
       "      <td>584</td>\n",
       "      <td>PROMOCJA!!! Drewniane Meble Ogrodowe Od Produc...</td>\n",
       "      <td>Oferuje bardzo ładne  a przede wszystkim wygod...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>900.0</td>\n",
       "      <td>-880.162637</td>\n",
       "      <td>70203.571429</td>\n",
       "      <td>55098.0</td>\n",
       "      <td>89643.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oferuje bardzo ładne  a przede wszystkim wygod...</td>\n",
       "      <td>2017_07</td>\n",
       "      <td>247</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>10503095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1496614785</td>\n",
       "      <td>584</td>\n",
       "      <td>Duży plac zabaw dla dzieci, huśtawka, zjeżdzal...</td>\n",
       "      <td>Solidny i estetycznie wykonany plac zabaw dla ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>-880.162637</td>\n",
       "      <td>70203.571429</td>\n",
       "      <td>55098.0</td>\n",
       "      <td>89643.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Solidny i estetycznie wykonany plac zabaw dla ...</td>\n",
       "      <td>2017_07</td>\n",
       "      <td>248</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>10577545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1740201284</td>\n",
       "      <td>584</td>\n",
       "      <td>Żyworódka pierzasta - 30 cm, także sok - rośli...</td>\n",
       "      <td>ŻYWORÓDKA PIERZASTA !\\nChyba najbardziej docen...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-880.162637</td>\n",
       "      <td>70203.571429</td>\n",
       "      <td>55098.0</td>\n",
       "      <td>89643.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ŻYWORÓDKA PIERZASTA !\\nChyba najbardziej docen...</td>\n",
       "      <td>2017_07</td>\n",
       "      <td>234</td>\n",
       "      <td>3977</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8563736</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>479354039</td>\n",
       "      <td>584</td>\n",
       "      <td>Trawa z rolki - PRODUCENT &lt;CITY&gt;, &lt;CITY&gt; - FOL...</td>\n",
       "      <td>TRAWNIKI ROLOWANE - SOLEC KUJAWSKI\\n\\nPlantacj...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>238</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-880.162637</td>\n",
       "      <td>70203.571429</td>\n",
       "      <td>55098.0</td>\n",
       "      <td>89643.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAWNIKI ROLOWANE - SOLEC KUJAWSKI\\n\\nPlantacj...</td>\n",
       "      <td>2017_07</td>\n",
       "      <td>225</td>\n",
       "      <td>1797</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>20801000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1861434792</td>\n",
       "      <td>584</td>\n",
       "      <td>kora sosnowa ogrodowa sortowana gruba srednia ...</td>\n",
       "      <td>Nasza firma Artfili-Twój Ogród zajmuje się pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-880.162637</td>\n",
       "      <td>70203.571429</td>\n",
       "      <td>55098.0</td>\n",
       "      <td>89643.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nasza firma Artfili-Twój Ogród zajmuje się pro...</td>\n",
       "      <td>2017_07</td>\n",
       "      <td>244</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5087688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          id  category_id  \\\n",
       "0           0  1909313589          584   \n",
       "1           1  1496614785          584   \n",
       "2           2  1740201284          584   \n",
       "3           3   479354039          584   \n",
       "4           4  1861434792          584   \n",
       "\n",
       "                                               title  \\\n",
       "0  PROMOCJA!!! Drewniane Meble Ogrodowe Od Produc...   \n",
       "1  Duży plac zabaw dla dzieci, huśtawka, zjeżdzal...   \n",
       "2  Żyworódka pierzasta - 30 cm, także sok - rośli...   \n",
       "3  Trawa z rolki - PRODUCENT <CITY>, <CITY> - FOL...   \n",
       "4  kora sosnowa ogrodowa sortowana gruba srednia ...   \n",
       "\n",
       "                                         description  predict_sold  \\\n",
       "0  Oferuje bardzo ładne  a przede wszystkim wygod...             0   \n",
       "1  Solidny i estetycznie wykonany plac zabaw dla ...             0   \n",
       "2  ŻYWORÓDKA PIERZASTA !\\nChyba najbardziej docen...             0   \n",
       "3  TRAWNIKI ROLOWANE - SOLEC KUJAWSKI\\n\\nPlantacj...             0   \n",
       "4  Nasza firma Artfili-Twój Ogród zajmuje się pro...             0   \n",
       "\n",
       "   predict_replies  predict_views  priceValue  derivative       average  \\\n",
       "0                0             39       900.0 -880.162637  70203.571429   \n",
       "1                0             88      2800.0 -880.162637  70203.571429   \n",
       "2                1             14        15.0 -880.162637  70203.571429   \n",
       "3               11            238        13.0 -880.162637  70203.571429   \n",
       "4                1             29         7.5 -880.162637  70203.571429   \n",
       "\n",
       "       min      max  private  exchange  free  price  new  \\\n",
       "0  55098.0  89643.0        1         0     0      1    1   \n",
       "1  55098.0  89643.0        1         0     0      1    1   \n",
       "2  55098.0  89643.0        1         0     0      1    1   \n",
       "3  55098.0  89643.0        0         0     0      1    1   \n",
       "4  55098.0  89643.0        0         0     0      1    1   \n",
       "\n",
       "                                    full_description   period  \\\n",
       "0  Oferuje bardzo ładne  a przede wszystkim wygod...  2017_07   \n",
       "1  Solidny i estetycznie wykonany plac zabaw dla ...  2017_07   \n",
       "2  ŻYWORÓDKA PIERZASTA !\\nChyba najbardziej docen...  2017_07   \n",
       "3  TRAWNIKI ROLOWANE - SOLEC KUJAWSKI\\n\\nPlantacj...  2017_07   \n",
       "4  Nasza firma Artfili-Twój Ogród zajmuje się pro...  2017_07   \n",
       "\n",
       "   description_len  full_description_len  paid_ads  nb_photos  photos_surface  \\\n",
       "0              247                   482         0         28        10503095   \n",
       "1              248                   294         0         21        10577545   \n",
       "2              234                  3977         0         15         8563736   \n",
       "3              225                  1797         0         36        20801000   \n",
       "4              244                  1098         0         15         5087688   \n",
       "\n",
       "   title_contains_phrase  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_of_sold(ad_df, category_id):\n",
    "    all_ads = len(ad_df[ad_df['category_id'] == category_id]['predict_sold'])\n",
    "    sold_ads = len(ad_df[(ad_df['category_id'] == category_id) & (ad_df['predict_sold'] == 1)]['predict_sold'])\n",
    "    return sold_ads / all_ads\n",
    "\n",
    "def find_categories_kinda_good(data_frame, non_zero=False):\n",
    "    categories = []\n",
    "    for i in range(1, 2000):\n",
    "        try:\n",
    "            get_percentage_of_sold(data_frame, i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "        else:\n",
    "            categories.append((i, get_percentage_of_sold(data_frame, i)))\n",
    "    return list(filter(lambda x: x[1] > 0, categories)) if non_zero \\\n",
    "            else categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cats = find_categories_kinda_good(data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "with open('learn/polish_stopwords.txt', 'r') as f:\n",
    "    stop_words = [line[:-1] for line in f]\n",
    "    \n",
    "numbers = []\n",
    "for i in range(1000):\n",
    "    numbers.append(str(i))\n",
    "numbers += ['00', '000', '01', '001', '011']\n",
    "stop_words += numbers\n",
    "stop_words += '!,\",#,$,%,&,(,),*,+,-,.,/,:,;,<,=,>,?,@,[,\\,\\,],^,_,`,{,|,},~,\\,t,\\,n'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_t = CountVectorizer(max_features=500)\n",
    "corpus_true = data[data['predict_sold'] == 1]['full_description']\n",
    "X_t = vectorizer_t.fit_transform(corpus_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_t = set(filter(lambda x: x not in stop_words, vectorizer_t.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 0.02531645569620253),\n",
       " (24, 0.018691588785046728),\n",
       " (25, 0.16666666666666666),\n",
       " (93, 0.06641476828549092),\n",
       " (100, 0.046877072006365206),\n",
       " (111, 0.09090909090909091),\n",
       " (140, 0.08144126357354393),\n",
       " (175, 0.05261018246167826),\n",
       " (180, 0.125),\n",
       " (188, 0.07692307692307693),\n",
       " (219, 0.03014982994760548),\n",
       " (224, 0.027286385674702193),\n",
       " (230, 0.031872464668779875),\n",
       " (231, 0.04805614221644587),\n",
       " (235, 0.05289147051261074),\n",
       " (236, 0.10411198600174978),\n",
       " (237, 0.11122881355932203),\n",
       " (238, 0.16176470588235295),\n",
       " (239, 0.11607142857142858),\n",
       " (240, 0.08095238095238096),\n",
       " (241, 0.08108108108108109),\n",
       " (244, 0.10133333333333333),\n",
       " (245, 0.13297872340425532),\n",
       " (246, 0.136),\n",
       " (247, 0.21875),\n",
       " (248, 0.15432098765432098),\n",
       " (249, 0.16981132075471697),\n",
       " (250, 0.14102564102564102),\n",
       " (251, 0.09556437071763434),\n",
       " (252, 0.13157894736842105),\n",
       " (253, 0.15853658536585366),\n",
       " (254, 0.175561797752809),\n",
       " (255, 0.13636363636363635),\n",
       " (256, 0.13043478260869565),\n",
       " (272, 0.02406417112299465),\n",
       " (279, 0.03322308563842571),\n",
       " (282, 0.06307819438752545),\n",
       " (292, 0.021492318526076772),\n",
       " (293, 0.025291576273386365),\n",
       " (294, 0.052083333333333336),\n",
       " (295, 0.05063291139240506),\n",
       " (297, 0.02702702702702703),\n",
       " (300, 0.05952380952380952),\n",
       " (306, 0.008871989860583017),\n",
       " (333, 0.037037037037037035),\n",
       " (375, 0.0625531914893617),\n",
       " (382, 0.08347317706923618),\n",
       " (383, 0.11363636363636363),\n",
       " (384, 0.058512396694214874),\n",
       " (385, 0.06993006993006994),\n",
       " (386, 0.10810684161199625),\n",
       " (387, 0.11664658776840763),\n",
       " (388, 0.10498533724340176),\n",
       " (390, 0.08498327100964377),\n",
       " (401, 0.02192190812488924),\n",
       " (405, 0.03675586088909086),\n",
       " (406, 0.03868613138686131),\n",
       " (431, 0.02411643604697038),\n",
       " (451, 0.03302725830488919),\n",
       " (461, 0.06644335975889405),\n",
       " (465, 0.04532954847866584),\n",
       " (488, 0.11325301204819277),\n",
       " (489, 0.1746031746031746),\n",
       " (490, 0.02857142857142857),\n",
       " (506, 0.02676683198671878),\n",
       " (516, 0.08193294202782021),\n",
       " (517, 0.0793806076529614),\n",
       " (522, 0.014705882352941176),\n",
       " (523, 0.02),\n",
       " (575, 0.02572112493772298),\n",
       " (584, 0.030268900464592425),\n",
       " (625, 0.021013597033374538),\n",
       " (626, 0.03961733466563044),\n",
       " (642, 0.020404422476263107),\n",
       " (683, 0.14583333333333334),\n",
       " (684, 0.12773722627737227),\n",
       " (685, 0.18181818181818182),\n",
       " (686, 0.15378548895899052),\n",
       " (687, 0.10833333333333334),\n",
       " (688, 0.125),\n",
       " (689, 0.12228571428571429),\n",
       " (690, 0.13170731707317074),\n",
       " (691, 0.22),\n",
       " (692, 0.05660377358490566),\n",
       " (693, 0.05825242718446602),\n",
       " (695, 0.125),\n",
       " (696, 0.12359550561797752),\n",
       " (697, 0.07407407407407407),\n",
       " (700, 0.14492753623188406),\n",
       " (704, 0.08433734939759036),\n",
       " (706, 0.18181818181818182),\n",
       " (712, 0.016666666666666666),\n",
       " (714, 0.05794506320954052),\n",
       " (715, 0.026674098256230593),\n",
       " (717, 0.07831654991243432),\n",
       " (718, 0.05823934524403633),\n",
       " (719, 0.06809405797936718),\n",
       " (720, 0.09380413057961359),\n",
       " (721, 0.05289090300799903),\n",
       " (722, 0.0595219469795741),\n",
       " (723, 0.06305564354344842),\n",
       " (724, 0.051477285997897936),\n",
       " (725, 0.050706512486740615),\n",
       " (726, 0.058204633204633205),\n",
       " (727, 0.050997285788988767),\n",
       " (728, 0.05667855727308759),\n",
       " (729, 0.06476297125793207),\n",
       " (732, 0.038174273858921165),\n",
       " (733, 0.007668469152199348),\n",
       " (734, 0.03511255370561856),\n",
       " (737, 0.06976744186046512),\n",
       " (741, 0.0196078431372549),\n",
       " (743, 0.10223157164234131),\n",
       " (745, 0.08343171979535616),\n",
       " (747, 0.08974358974358974),\n",
       " (753, 0.04534493685561034),\n",
       " (755, 0.024410917104593997),\n",
       " (761, 0.04855683664783719),\n",
       " (765, 0.02082255046382928),\n",
       " (769, 0.06042301331708591),\n",
       " (771, 0.06622943468146529),\n",
       " (773, 0.039935026346024326),\n",
       " (1155, 0.07907826616587149),\n",
       " (1157, 0.029561896565634835),\n",
       " (1159, 0.029106257453084792),\n",
       " (1161, 0.041926402573899055),\n",
       " (1163, 0.036875827007451775),\n",
       " (1165, 0.016956428418115475),\n",
       " (1167, 0.022620055642917625),\n",
       " (1169, 0.05855265620905245),\n",
       " (1173, 0.022042911024547085),\n",
       " (1175, 0.048294874412905864),\n",
       " (1177, 0.03407517836226174),\n",
       " (1179, 0.02871556072953046),\n",
       " (1181, 0.03435615001311303),\n",
       " (1183, 0.031714568880079286),\n",
       " (1185, 0.046433878157503716),\n",
       " (1187, 0.04718779790276454),\n",
       " (1189, 0.0404883011190234),\n",
       " (1191, 0.024801464724184798),\n",
       " (1193, 0.04019232164409943),\n",
       " (1195, 0.03392652721407014),\n",
       " (1197, 0.058607679983461676),\n",
       " (1199, 0.07372727988039972),\n",
       " (1201, 0.07791878172588833),\n",
       " (1203, 0.052122740647330815),\n",
       " (1205, 0.044667274384685506),\n",
       " (1207, 0.05572116487044256),\n",
       " (1209, 0.045024569472766965),\n",
       " (1211, 0.045304777594728174),\n",
       " (1217, 0.11279949558638083),\n",
       " (1265, 0.014841188273870699),\n",
       " (1267, 0.024311392732445362),\n",
       " (1271, 0.1844331641285956),\n",
       " (1273, 0.07163850110213078),\n",
       " (1275, 0.06703470031545741),\n",
       " (1277, 0.09801136363636363),\n",
       " (1279, 0.05405405405405406),\n",
       " (1281, 0.05202312138728324),\n",
       " (1283, 0.03935784567581564),\n",
       " (1285, 0.031724137931034485),\n",
       " (1287, 0.12475393700787402),\n",
       " (1291, 0.027188484876993272),\n",
       " (1295, 0.09790845710821461),\n",
       " (1297, 0.05993713909801915),\n",
       " (1299, 0.07550809507406131),\n",
       " (1301, 0.07259073842302878),\n",
       " (1303, 0.0318403035552256),\n",
       " (1319, 0.04728773229721996),\n",
       " (1335, 0.056910569105691054),\n",
       " (1375, 0.037037037037037035),\n",
       " (1385, 0.2),\n",
       " (1393, 0.06666666666666667),\n",
       " (1397, 0.0425531914893617),\n",
       " (1399, 0.035398230088495575),\n",
       " (1401, 0.07692307692307693),\n",
       " (1403, 0.05870020964360587),\n",
       " (1407, 0.030873780418847092),\n",
       " (1415, 0.04681145386637156),\n",
       " (1417, 0.03374616520849903),\n",
       " (1419, 0.028626736723659493),\n",
       " (1455, 0.1073483358823101),\n",
       " (1457, 0.1033167009098914),\n",
       " (1459, 0.10927004030452306),\n",
       " (1461, 0.05507246376811594),\n",
       " (1479, 0.11314566821535939),\n",
       " (1483, 0.12018445575943895),\n",
       " (1491, 0.02747971735147867),\n",
       " (1493, 0.017352185089974295),\n",
       " (1495, 0.01008533747090768),\n",
       " (1497, 0.012048192771084338),\n",
       " (1499, 0.035171276790620994),\n",
       " (1503, 0.007462686567164179),\n",
       " (1509, 0.004219409282700422),\n",
       " (1511, 0.0072992700729927005),\n",
       " (1513, 0.029044701611073292),\n",
       " (1515, 0.020654044750430294),\n",
       " (1517, 0.03384270050936718),\n",
       " (1523, 0.04040743981512643),\n",
       " (1525, 0.03981674302374011),\n",
       " (1527, 0.07153885743695317),\n",
       " (1530, 0.025033266799733864),\n",
       " (1532, 0.12962962962962962),\n",
       " (1534, 0.09433962264150944),\n",
       " (1536, 0.1267605633802817),\n",
       " (1540, 0.04)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2016',\n",
       " '5cm',\n",
       " 'aparat',\n",
       " 'aukcje',\n",
       " 'aukcji',\n",
       " 'bateria',\n",
       " 'bdb',\n",
       " 'białe',\n",
       " 'biały',\n",
       " 'bluza',\n",
       " 'bluzka',\n",
       " 'body',\n",
       " 'brak',\n",
       " 'buciki',\n",
       " 'buty',\n",
       " 'bądź',\n",
       " 'całkowita',\n",
       " 'całość',\n",
       " 'cd',\n",
       " 'cena',\n",
       " 'cenie',\n",
       " 'ceny',\n",
       " 'chłopca',\n",
       " 'city',\n",
       " 'cm',\n",
       " 'czarne',\n",
       " 'czarny',\n",
       " 'czas',\n",
       " 'części',\n",
       " 'dane',\n",
       " 'dl',\n",
       " 'dni',\n",
       " 'dobry',\n",
       " 'dobrym',\n",
       " 'dodatkowe',\n",
       " 'dodatkowo',\n",
       " 'dole',\n",
       " 'domu',\n",
       " 'dotyczy',\n",
       " 'duże',\n",
       " 'duży',\n",
       " 'dvd',\n",
       " 'dysk',\n",
       " 'działa',\n",
       " 'dzieci',\n",
       " 'dziecka',\n",
       " 'dziecko',\n",
       " 'dziecku',\n",
       " 'dziewczynki',\n",
       " 'dzień',\n",
       " 'dzięki',\n",
       " 'dzwonić',\n",
       " 'dł',\n",
       " 'długość',\n",
       " 'ekran',\n",
       " 'etui',\n",
       " 'firmy',\n",
       " 'fotelik',\n",
       " 'galaxy',\n",
       " 'gb',\n",
       " 'gorąco',\n",
       " 'gra',\n",
       " 'gratis',\n",
       " 'gry',\n",
       " 'gwarancja',\n",
       " 'gwarancji',\n",
       " 'głębokość',\n",
       " 'hd',\n",
       " 'idealna',\n",
       " 'idealne',\n",
       " 'idealnie',\n",
       " 'idealny',\n",
       " 'idealnym',\n",
       " 'ikea',\n",
       " 'ilości',\n",
       " 'ilość',\n",
       " 'informacji',\n",
       " 'instrukcja',\n",
       " 'intel',\n",
       " 'iphone',\n",
       " 'istnieje',\n",
       " 'itp',\n",
       " 'jakości',\n",
       " 'jazdy',\n",
       " 'jednej',\n",
       " 'jednym',\n",
       " 'jedynie',\n",
       " 'kabel',\n",
       " 'karta',\n",
       " 'kg',\n",
       " 'kolor',\n",
       " 'kolorze',\n",
       " 'kombinezon',\n",
       " 'komplecie',\n",
       " 'komplet',\n",
       " 'kontakt',\n",
       " 'kontaktu',\n",
       " 'konto',\n",
       " 'koszt',\n",
       " 'koszula',\n",
       " 'koła',\n",
       " 'książka',\n",
       " 'książki',\n",
       " 'kupione',\n",
       " 'kupiony',\n",
       " 'kupna',\n",
       " 'kurierem',\n",
       " 'kurtka',\n",
       " 'kurtkę',\n",
       " 'laptop',\n",
       " 'lata',\n",
       " 'lekko',\n",
       " 'list',\n",
       " 'marki',\n",
       " 'materiał',\n",
       " 'materiału',\n",
       " 'max',\n",
       " 'małe',\n",
       " 'meble',\n",
       " 'metki',\n",
       " 'miesięcy',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'moc',\n",
       " 'model',\n",
       " 'mogę',\n",
       " 'moich',\n",
       " 'możliwa',\n",
       " 'możliwość',\n",
       " 'możliwy',\n",
       " 'należy',\n",
       " 'name',\n",
       " 'negocjacji',\n",
       " 'niestety',\n",
       " 'nike',\n",
       " 'nogawki',\n",
       " 'normalne',\n",
       " 'nosi',\n",
       " 'nowa',\n",
       " 'nowe',\n",
       " 'nowy',\n",
       " 'nową',\n",
       " 'np',\n",
       " 'nr',\n",
       " 'numerem',\n",
       " 'obejrzenia',\n",
       " 'oceniam',\n",
       " 'oczywiście',\n",
       " 'odbior',\n",
       " 'odbioru',\n",
       " 'odbiór',\n",
       " 'oferuję',\n",
       " 'ogłoszenia',\n",
       " 'ogłoszeń',\n",
       " 'ok',\n",
       " 'olx',\n",
       " 'opakowanie',\n",
       " 'opis',\n",
       " 'oryginalna',\n",
       " 'oryginalne',\n",
       " 'oryginalny',\n",
       " 'osobistego',\n",
       " 'osobisty',\n",
       " 'pachami',\n",
       " 'pachy',\n",
       " 'paczka',\n",
       " 'pamięci',\n",
       " 'pamięć',\n",
       " 'paragon',\n",
       " 'pas',\n",
       " 'pasie',\n",
       " 'pasuje',\n",
       " 'pełni',\n",
       " 'phone',\n",
       " 'pisać',\n",
       " 'plam',\n",
       " 'plus',\n",
       " 'pobraniem',\n",
       " 'pocztą',\n",
       " 'podręcznik',\n",
       " 'pojemność',\n",
       " 'pokrowiec',\n",
       " 'polecam',\n",
       " 'polecony',\n",
       " 'polskiej',\n",
       " 'posiada',\n",
       " 'posiadają',\n",
       " 'posiadam',\n",
       " 'postcode',\n",
       " 'pozdrawiam',\n",
       " 'pozostałe',\n",
       " 'pozostałych',\n",
       " 'pracy',\n",
       " 'praktycznie',\n",
       " 'prezent',\n",
       " 'procesor',\n",
       " 'producenta',\n",
       " 'produkt',\n",
       " 'proszę',\n",
       " 'przedmiotem',\n",
       " 'przesyłka',\n",
       " 'przesyłki',\n",
       " 'przesyłkę',\n",
       " 'przodu',\n",
       " 'przypadku',\n",
       " 'przód',\n",
       " 'pudełko',\n",
       " 'pytań',\n",
       " 'płyta',\n",
       " 'ram',\n",
       " 'raz',\n",
       " 'razem',\n",
       " 'razie',\n",
       " 'razy',\n",
       " 'regulacja',\n",
       " 'rok',\n",
       " 'rower',\n",
       " 'roz',\n",
       " 'rozm',\n",
       " 'rozmiar',\n",
       " 'rozmiarze',\n",
       " 'rzeczy',\n",
       " 'rękaw',\n",
       " 'rękawa',\n",
       " 'sa',\n",
       " 'samsung',\n",
       " 'serdecznie',\n",
       " 'sim',\n",
       " 'sklepie',\n",
       " 'skóry',\n",
       " 'skład',\n",
       " 'sms',\n",
       " 'sony',\n",
       " 'specyfikacja',\n",
       " 'spodenki',\n",
       " 'spodnie',\n",
       " 'sprawna',\n",
       " 'sprawne',\n",
       " 'sprawny',\n",
       " 'sprzedaje',\n",
       " 'sprzedaję',\n",
       " 'sprzedam',\n",
       " 'sprzedania',\n",
       " 'sprzedaż',\n",
       " 'sprzedaży',\n",
       " 'sprzęt',\n",
       " 'stan',\n",
       " 'stanie',\n",
       " 'stolik',\n",
       " 'street',\n",
       " 'stronie',\n",
       " 'strony',\n",
       " 'sukienka',\n",
       " 'sukienkę',\n",
       " 'super',\n",
       " 'surname',\n",
       " 'system',\n",
       " 'szer',\n",
       " 'szerokość',\n",
       " 'szt',\n",
       " 'sztuk',\n",
       " 'sztuki',\n",
       " 'sztukę',\n",
       " 'słuchawki',\n",
       " 'techniczne',\n",
       " 'technicznie',\n",
       " 'tel',\n",
       " 'telefon',\n",
       " 'telefonicznie',\n",
       " 'telefoniczny',\n",
       " 'telefonu',\n",
       " 'temu',\n",
       " 'terenie',\n",
       " 'transport',\n",
       " 'trzy',\n",
       " 'typu',\n",
       " 'tył',\n",
       " 'tyłu',\n",
       " 'ubranka',\n",
       " 'url',\n",
       " 'urządzenie',\n",
       " 'usb',\n",
       " 'uszkodzeń',\n",
       " 'użytkowania',\n",
       " 'używana',\n",
       " 'używane',\n",
       " 'używany',\n",
       " 'vat',\n",
       " 'waga',\n",
       " 'wchodzi',\n",
       " 'widać',\n",
       " 'widoczne',\n",
       " 'widoczny',\n",
       " 'windows',\n",
       " 'witam',\n",
       " 'wizualny',\n",
       " 'wkładka',\n",
       " 'wkładki',\n",
       " 'wraz',\n",
       " 'wygodne',\n",
       " 'wykonana',\n",
       " 'wykonane',\n",
       " 'wykonany',\n",
       " 'wymiarach',\n",
       " 'wymiary',\n",
       " 'wys',\n",
       " 'wysokiej',\n",
       " 'wysokości',\n",
       " 'wysokość',\n",
       " 'wysylka',\n",
       " 'wysyłam',\n",
       " 'wysyłamy',\n",
       " 'wysyłka',\n",
       " 'wysyłki',\n",
       " 'wyłącznie',\n",
       " 'wyświetlacz',\n",
       " 'wózek',\n",
       " 'wózka',\n",
       " 'xl',\n",
       " 'zabawka',\n",
       " 'zachęcam',\n",
       " 'zainteresowanych',\n",
       " 'zakupie',\n",
       " 'zakupiony',\n",
       " 'zakupu',\n",
       " 'zamek',\n",
       " 'zaoferowania',\n",
       " 'zapewnia',\n",
       " 'zapinana',\n",
       " 'zapraszam',\n",
       " 'zapraszamy',\n",
       " 'zara',\n",
       " 'zarówno',\n",
       " 'zasilacz',\n",
       " 'zawiera',\n",
       " 'założona',\n",
       " 'założone',\n",
       " 'zdjęcia',\n",
       " 'zdjęciach',\n",
       " 'zdjęciu',\n",
       " 'zdjęć',\n",
       " 'zegarek',\n",
       " 'zestaw',\n",
       " 'zestawie',\n",
       " 'zestawu',\n",
       " 'zl',\n",
       " 'znajduje',\n",
       " 'ładowarka',\n",
       " 'łóżko',\n",
       " 'ślady',\n",
       " 'śladów',\n",
       " 'średnica',\n",
       " 'środku'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '100',\n",
       " '104',\n",
       " '11',\n",
       " '110',\n",
       " '12',\n",
       " '120',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '200',\n",
       " '2016',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '30',\n",
       " '32',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '42',\n",
       " '44',\n",
       " '45',\n",
       " '48',\n",
       " '50',\n",
       " '56',\n",
       " '5cm',\n",
       " '60',\n",
       " '62',\n",
       " '68',\n",
       " '70',\n",
       " '74',\n",
       " '80',\n",
       " '86',\n",
       " '90',\n",
       " '92',\n",
       " '98',\n",
       " 'aby',\n",
       " 'ale',\n",
       " 'ani',\n",
       " 'aparat',\n",
       " 'aukcje',\n",
       " 'aukcji',\n",
       " 'bardzo',\n",
       " 'bateria',\n",
       " 'bdb',\n",
       " 'bez',\n",
       " 'białe',\n",
       " 'biały',\n",
       " 'bluza',\n",
       " 'bluzka',\n",
       " 'bo',\n",
       " 'body',\n",
       " 'brak',\n",
       " 'buciki',\n",
       " 'buty',\n",
       " 'być',\n",
       " 'był',\n",
       " 'była',\n",
       " 'były',\n",
       " 'bądź',\n",
       " 'będzie',\n",
       " 'całkowita',\n",
       " 'całość',\n",
       " 'cały',\n",
       " 'cd',\n",
       " 'cena',\n",
       " 'cenie',\n",
       " 'ceny',\n",
       " 'chłopca',\n",
       " 'city',\n",
       " 'cm',\n",
       " 'co',\n",
       " 'czarne',\n",
       " 'czarny',\n",
       " 'czas',\n",
       " 'czy',\n",
       " 'części',\n",
       " 'dane',\n",
       " 'dl',\n",
       " 'dla',\n",
       " 'dlatego',\n",
       " 'dni',\n",
       " 'do',\n",
       " 'dobry',\n",
       " 'dobrym',\n",
       " 'dobrze',\n",
       " 'dodatkowe',\n",
       " 'dodatkowo',\n",
       " 'dole',\n",
       " 'domu',\n",
       " 'dotyczy',\n",
       " 'duże',\n",
       " 'duży',\n",
       " 'dvd',\n",
       " 'dwa',\n",
       " 'dwie',\n",
       " 'dysk',\n",
       " 'działa',\n",
       " 'dzieci',\n",
       " 'dziecka',\n",
       " 'dziecko',\n",
       " 'dziecku',\n",
       " 'dziewczynki',\n",
       " 'dzień',\n",
       " 'dzięki',\n",
       " 'dzwonić',\n",
       " 'dł',\n",
       " 'długość',\n",
       " 'ekran',\n",
       " 'etui',\n",
       " 'firmy',\n",
       " 'fotelik',\n",
       " 'galaxy',\n",
       " 'gb',\n",
       " 'gdyż',\n",
       " 'go',\n",
       " 'gorąco',\n",
       " 'gra',\n",
       " 'gratis',\n",
       " 'gry',\n",
       " 'gwarancja',\n",
       " 'gwarancji',\n",
       " 'głębokość',\n",
       " 'hd',\n",
       " 'ich',\n",
       " 'idealna',\n",
       " 'idealne',\n",
       " 'idealnie',\n",
       " 'idealny',\n",
       " 'idealnym',\n",
       " 'ikea',\n",
       " 'ilości',\n",
       " 'ilość',\n",
       " 'informacji',\n",
       " 'inne',\n",
       " 'innych',\n",
       " 'instrukcja',\n",
       " 'intel',\n",
       " 'iphone',\n",
       " 'istnieje',\n",
       " 'itp',\n",
       " 'jak',\n",
       " 'jako',\n",
       " 'jakości',\n",
       " 'jazdy',\n",
       " 'je',\n",
       " 'jeden',\n",
       " 'jedna',\n",
       " 'jednak',\n",
       " 'jednej',\n",
       " 'jednym',\n",
       " 'jedynie',\n",
       " 'jego',\n",
       " 'jej',\n",
       " 'jest',\n",
       " 'jeszcze',\n",
       " 'jeśli',\n",
       " 'już',\n",
       " 'ją',\n",
       " 'kabel',\n",
       " 'karta',\n",
       " 'kg',\n",
       " 'kilka',\n",
       " 'kolor',\n",
       " 'kolorze',\n",
       " 'kombinezon',\n",
       " 'komplecie',\n",
       " 'komplet',\n",
       " 'kontakt',\n",
       " 'kontaktu',\n",
       " 'konto',\n",
       " 'koszt',\n",
       " 'koszula',\n",
       " 'koła',\n",
       " 'książka',\n",
       " 'książki',\n",
       " 'która',\n",
       " 'które',\n",
       " 'który',\n",
       " 'kupione',\n",
       " 'kupiony',\n",
       " 'kupna',\n",
       " 'kurierem',\n",
       " 'kurtka',\n",
       " 'kurtkę',\n",
       " 'laptop',\n",
       " 'lat',\n",
       " 'lata',\n",
       " 'lecz',\n",
       " 'lekko',\n",
       " 'list',\n",
       " 'lub',\n",
       " 'ma',\n",
       " 'mają',\n",
       " 'mam',\n",
       " 'marki',\n",
       " 'materiał',\n",
       " 'materiału',\n",
       " 'max',\n",
       " 'małe',\n",
       " 'mało',\n",
       " 'meble',\n",
       " 'metki',\n",
       " 'mi',\n",
       " 'miesięcy',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'mnie',\n",
       " 'moc',\n",
       " 'model',\n",
       " 'mogę',\n",
       " 'moich',\n",
       " 'moje',\n",
       " 'może',\n",
       " 'możliwa',\n",
       " 'możliwość',\n",
       " 'możliwy',\n",
       " 'można',\n",
       " 'na',\n",
       " 'należy',\n",
       " 'name',\n",
       " 'nawet',\n",
       " 'negocjacji',\n",
       " 'nie',\n",
       " 'niestety',\n",
       " 'nigdy',\n",
       " 'nike',\n",
       " 'nim',\n",
       " 'nogawki',\n",
       " 'normalne',\n",
       " 'nosi',\n",
       " 'nowa',\n",
       " 'nowe',\n",
       " 'nowy',\n",
       " 'nową',\n",
       " 'np',\n",
       " 'nr',\n",
       " 'numerem',\n",
       " 'obejrzenia',\n",
       " 'oceniam',\n",
       " 'oczywiście',\n",
       " 'od',\n",
       " 'odbior',\n",
       " 'odbioru',\n",
       " 'odbiór',\n",
       " 'oferuję',\n",
       " 'ogłoszenia',\n",
       " 'ogłoszeń',\n",
       " 'ok',\n",
       " 'około',\n",
       " 'olx',\n",
       " 'opakowanie',\n",
       " 'opis',\n",
       " 'oraz',\n",
       " 'oryginalna',\n",
       " 'oryginalne',\n",
       " 'oryginalny',\n",
       " 'osobistego',\n",
       " 'osobisty',\n",
       " 'pachami',\n",
       " 'pachy',\n",
       " 'paczka',\n",
       " 'pamięci',\n",
       " 'pamięć',\n",
       " 'paragon',\n",
       " 'pas',\n",
       " 'pasie',\n",
       " 'pasuje',\n",
       " 'pełni',\n",
       " 'phone',\n",
       " 'pisać',\n",
       " 'plam',\n",
       " 'plus',\n",
       " 'po',\n",
       " 'pobraniem',\n",
       " 'pocztą',\n",
       " 'pod',\n",
       " 'podczas',\n",
       " 'podręcznik',\n",
       " 'pojemność',\n",
       " 'pokrowiec',\n",
       " 'polecam',\n",
       " 'polecony',\n",
       " 'polskiej',\n",
       " 'ponieważ',\n",
       " 'posiada',\n",
       " 'posiadają',\n",
       " 'posiadam',\n",
       " 'postcode',\n",
       " 'pozdrawiam',\n",
       " 'pozostałe',\n",
       " 'pozostałych',\n",
       " 'pracy',\n",
       " 'praktycznie',\n",
       " 'prawie',\n",
       " 'prezent',\n",
       " 'procesor',\n",
       " 'producenta',\n",
       " 'produkt',\n",
       " 'proszę',\n",
       " 'przed',\n",
       " 'przedmiotem',\n",
       " 'przesyłka',\n",
       " 'przesyłki',\n",
       " 'przesyłkę',\n",
       " 'przez',\n",
       " 'przodu',\n",
       " 'przy',\n",
       " 'przypadku',\n",
       " 'przód',\n",
       " 'pudełko',\n",
       " 'pytań',\n",
       " 'płyta',\n",
       " 'ram',\n",
       " 'raz',\n",
       " 'razem',\n",
       " 'razie',\n",
       " 'razy',\n",
       " 'regulacja',\n",
       " 'rok',\n",
       " 'roku',\n",
       " 'rower',\n",
       " 'roz',\n",
       " 'rozm',\n",
       " 'rozmiar',\n",
       " 'rozmiarze',\n",
       " 'rzeczy',\n",
       " 'również',\n",
       " 'rękaw',\n",
       " 'rękawa',\n",
       " 'sa',\n",
       " 'samsung',\n",
       " 'serdecznie',\n",
       " 'sie',\n",
       " 'sim',\n",
       " 'się',\n",
       " 'sklepie',\n",
       " 'skóry',\n",
       " 'skład',\n",
       " 'sms',\n",
       " 'sobie',\n",
       " 'sony',\n",
       " 'specyfikacja',\n",
       " 'spodenki',\n",
       " 'spodnie',\n",
       " 'sprawna',\n",
       " 'sprawne',\n",
       " 'sprawny',\n",
       " 'sprzedaje',\n",
       " 'sprzedaję',\n",
       " 'sprzedam',\n",
       " 'sprzedania',\n",
       " 'sprzedaż',\n",
       " 'sprzedaży',\n",
       " 'sprzęt',\n",
       " 'stan',\n",
       " 'stanie',\n",
       " 'stolik',\n",
       " 'street',\n",
       " 'stronie',\n",
       " 'strony',\n",
       " 'sukienka',\n",
       " 'sukienkę',\n",
       " 'super',\n",
       " 'surname',\n",
       " 'system',\n",
       " 'szer',\n",
       " 'szerokość',\n",
       " 'szt',\n",
       " 'sztuk',\n",
       " 'sztuki',\n",
       " 'sztukę',\n",
       " 'są',\n",
       " 'słuchawki',\n",
       " 'tak',\n",
       " 'także',\n",
       " 'techniczne',\n",
       " 'technicznie',\n",
       " 'tego',\n",
       " 'tej',\n",
       " 'tel',\n",
       " 'telefon',\n",
       " 'telefonicznie',\n",
       " 'telefoniczny',\n",
       " 'telefonu',\n",
       " 'temu',\n",
       " 'ten',\n",
       " 'terenie',\n",
       " 'też',\n",
       " 'to',\n",
       " 'transport',\n",
       " 'trzy',\n",
       " 'tylko',\n",
       " 'tym',\n",
       " 'typu',\n",
       " 'tył',\n",
       " 'tyłu',\n",
       " 'ubranka',\n",
       " 'url',\n",
       " 'urządzenie',\n",
       " 'usb',\n",
       " 'uszkodzeń',\n",
       " 'użytkowania',\n",
       " 'używana',\n",
       " 'używane',\n",
       " 'używany',\n",
       " 'vat',\n",
       " 'waga',\n",
       " 'wchodzi',\n",
       " 'we',\n",
       " 'widać',\n",
       " 'widoczne',\n",
       " 'widoczny',\n",
       " 'wiele',\n",
       " 'windows',\n",
       " 'witam',\n",
       " 'wizualny',\n",
       " 'więc',\n",
       " 'więcej',\n",
       " 'wkładka',\n",
       " 'wkładki',\n",
       " 'wraz',\n",
       " 'wszystkie',\n",
       " 'wszystko',\n",
       " 'wygodne',\n",
       " 'wykonana',\n",
       " 'wykonane',\n",
       " 'wykonany',\n",
       " 'wymiarach',\n",
       " 'wymiary',\n",
       " 'wys',\n",
       " 'wysokiej',\n",
       " 'wysokości',\n",
       " 'wysokość',\n",
       " 'wysylka',\n",
       " 'wysyłam',\n",
       " 'wysyłamy',\n",
       " 'wysyłka',\n",
       " 'wysyłki',\n",
       " 'wyłącznie',\n",
       " 'wyświetlacz',\n",
       " 'wózek',\n",
       " 'wózka',\n",
       " 'xl',\n",
       " 'za',\n",
       " 'zabawka',\n",
       " 'zachęcam',\n",
       " 'zainteresowanych',\n",
       " 'zakupie',\n",
       " 'zakupiony',\n",
       " 'zakupu',\n",
       " 'zamek',\n",
       " 'zaoferowania',\n",
       " 'zapewnia',\n",
       " 'zapinana',\n",
       " 'zapraszam',\n",
       " 'zapraszamy',\n",
       " 'zara',\n",
       " 'zarówno',\n",
       " 'zasilacz',\n",
       " 'zawiera',\n",
       " 'założona',\n",
       " 'założone',\n",
       " 'zdjęcia',\n",
       " 'zdjęciach',\n",
       " 'zdjęciu',\n",
       " 'zdjęć',\n",
       " 'ze',\n",
       " 'zegarek',\n",
       " 'zestaw',\n",
       " 'zestawie',\n",
       " 'zestawu',\n",
       " 'zl',\n",
       " 'znajduje',\n",
       " 'został',\n",
       " 'zł',\n",
       " 'ładowarka',\n",
       " 'łóżko',\n",
       " 'ślady',\n",
       " 'śladów',\n",
       " 'średnica',\n",
       " 'środku',\n",
       " 'żadnych',\n",
       " 'że']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_t.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn.dataset_creator import run as run_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing started.\n"
     ]
    }
   ],
   "source": [
    "data = run_processing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vec = vectorizer_t.transform(data[data['predict_sold'] == 1]['full_description'].head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "11\n",
      "41\n",
      "22\n",
      "41\n",
      "4\n",
      "45\n",
      "31\n",
      "14\n",
      "20\n",
      "9\n",
      "15\n",
      "13\n",
      "11\n",
      "13\n",
      "80\n",
      "97\n",
      "15\n",
      "1\n",
      "4\n",
      "17\n",
      "12\n",
      "5\n",
      "20\n",
      "10\n",
      "9\n",
      "18\n",
      "10\n",
      "21\n",
      "8\n",
      "25\n",
      "17\n",
      "14\n",
      "43\n",
      "20\n",
      "8\n",
      "4\n",
      "15\n",
      "16\n",
      "7\n",
      "50\n",
      "4\n",
      "6\n",
      "6\n",
      "57\n",
      "15\n",
      "11\n",
      "31\n",
      "102\n",
      "15\n",
      "9\n",
      "7\n",
      "57\n",
      "37\n",
      "6\n",
      "6\n",
      "17\n",
      "13\n",
      "5\n",
      "3\n",
      "8\n",
      "4\n",
      "2\n",
      "3\n",
      "35\n",
      "1\n",
      "31\n",
      "12\n",
      "9\n",
      "15\n",
      "21\n",
      "10\n",
      "0\n",
      "25\n",
      "19\n",
      "7\n",
      "6\n",
      "34\n",
      "2\n",
      "8\n",
      "16\n",
      "7\n",
      "1\n",
      "12\n",
      "44\n",
      "11\n",
      "6\n",
      "24\n",
      "48\n",
      "14\n",
      "7\n",
      "120\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "2\n",
      "18\n",
      "13\n",
      "23\n",
      "12\n",
      "3\n",
      "39\n",
      "14\n",
      "9\n",
      "7\n",
      "30\n",
      "30\n",
      "15\n",
      "6\n",
      "8\n",
      "6\n",
      "1\n",
      "23\n",
      "15\n",
      "10\n",
      "9\n",
      "4\n",
      "2\n",
      "10\n",
      "3\n",
      "9\n",
      "6\n",
      "80\n",
      "12\n",
      "14\n",
      "3\n",
      "14\n",
      "18\n",
      "6\n",
      "46\n",
      "6\n",
      "13\n",
      "25\n",
      "12\n",
      "7\n",
      "8\n",
      "3\n",
      "5\n",
      "4\n",
      "13\n",
      "0\n",
      "8\n",
      "11\n",
      "6\n",
      "6\n",
      "2\n",
      "9\n",
      "9\n",
      "31\n",
      "8\n",
      "3\n",
      "10\n",
      "4\n",
      "3\n",
      "28\n",
      "13\n",
      "34\n",
      "5\n",
      "15\n",
      "8\n",
      "12\n",
      "6\n",
      "5\n",
      "19\n",
      "35\n",
      "5\n",
      "3\n",
      "8\n",
      "31\n",
      "18\n",
      "4\n",
      "10\n",
      "10\n",
      "2\n",
      "9\n",
      "37\n",
      "6\n",
      "18\n",
      "21\n",
      "6\n",
      "3\n",
      "20\n",
      "13\n",
      "14\n",
      "19\n",
      "1\n",
      "23\n",
      "8\n",
      "46\n",
      "3\n",
      "16\n",
      "44\n",
      "5\n",
      "9\n",
      "15\n",
      "19\n",
      "4\n",
      "7\n",
      "12\n",
      "8\n",
      "31\n",
      "46\n",
      "1\n",
      "8\n",
      "13\n",
      "10\n",
      "20\n",
      "5\n",
      "10\n",
      "1\n",
      "6\n",
      "24\n",
      "13\n",
      "9\n",
      "8\n",
      "29\n",
      "11\n",
      "5\n",
      "2\n",
      "19\n",
      "2\n",
      "14\n",
      "2\n",
      "2\n",
      "10\n",
      "2\n",
      "17\n",
      "9\n",
      "8\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "4\n",
      "6\n",
      "11\n",
      "8\n",
      "3\n",
      "2\n",
      "10\n",
      "20\n",
      "5\n",
      "68\n",
      "22\n",
      "9\n",
      "27\n",
      "14\n",
      "4\n",
      "9\n",
      "6\n",
      "6\n",
      "25\n",
      "7\n",
      "8\n",
      "30\n",
      "5\n",
      "38\n",
      "11\n",
      "34\n",
      "26\n",
      "13\n",
      "16\n",
      "3\n",
      "23\n",
      "7\n",
      "5\n",
      "2\n",
      "18\n",
      "8\n",
      "16\n",
      "6\n",
      "11\n",
      "5\n",
      "11\n",
      "3\n",
      "15\n",
      "4\n",
      "4\n",
      "8\n",
      "7\n",
      "41\n",
      "32\n",
      "17\n",
      "73\n",
      "2\n",
      "16\n",
      "4\n",
      "24\n",
      "16\n",
      "1\n",
      "7\n",
      "23\n",
      "4\n",
      "12\n",
      "24\n",
      "9\n",
      "8\n",
      "7\n",
      "2\n",
      "7\n",
      "2\n",
      "27\n",
      "8\n",
      "5\n",
      "16\n",
      "16\n",
      "5\n",
      "19\n",
      "7\n",
      "15\n",
      "12\n",
      "27\n",
      "13\n",
      "9\n",
      "16\n",
      "14\n",
      "3\n",
      "16\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "7\n",
      "49\n",
      "2\n",
      "27\n",
      "10\n",
      "32\n",
      "2\n",
      "39\n",
      "6\n",
      "5\n",
      "17\n",
      "10\n",
      "10\n",
      "28\n",
      "9\n",
      "13\n",
      "40\n",
      "11\n",
      "8\n",
      "24\n",
      "10\n",
      "33\n",
      "4\n",
      "9\n",
      "19\n",
      "100\n",
      "7\n",
      "26\n",
      "23\n",
      "0\n",
      "19\n",
      "1\n",
      "132\n",
      "30\n",
      "6\n",
      "18\n",
      "31\n",
      "15\n",
      "28\n",
      "26\n",
      "10\n",
      "13\n",
      "50\n",
      "12\n",
      "57\n",
      "5\n",
      "3\n",
      "43\n",
      "8\n",
      "40\n",
      "4\n",
      "72\n",
      "16\n",
      "27\n",
      "7\n",
      "4\n",
      "13\n",
      "17\n",
      "20\n",
      "21\n",
      "29\n",
      "9\n",
      "15\n",
      "11\n",
      "11\n",
      "23\n",
      "22\n",
      "6\n",
      "27\n",
      "28\n",
      "35\n",
      "17\n",
      "7\n",
      "6\n",
      "5\n",
      "30\n",
      "19\n",
      "26\n",
      "4\n",
      "23\n",
      "34\n",
      "24\n",
      "39\n",
      "14\n",
      "3\n",
      "3\n",
      "3\n",
      "21\n",
      "3\n",
      "30\n",
      "4\n",
      "8\n",
      "5\n",
      "15\n",
      "18\n",
      "3\n",
      "4\n",
      "14\n",
      "5\n",
      "12\n",
      "35\n",
      "3\n",
      "5\n",
      "15\n",
      "17\n",
      "25\n",
      "10\n",
      "35\n",
      "3\n",
      "11\n",
      "16\n",
      "10\n",
      "21\n",
      "46\n",
      "10\n",
      "17\n",
      "14\n",
      "32\n",
      "19\n",
      "6\n",
      "38\n",
      "14\n",
      "65\n",
      "7\n",
      "10\n",
      "53\n",
      "28\n",
      "8\n",
      "20\n",
      "14\n",
      "28\n",
      "11\n",
      "8\n",
      "15\n",
      "16\n",
      "10\n",
      "47\n",
      "12\n",
      "12\n",
      "9\n",
      "29\n",
      "20\n",
      "6\n",
      "25\n",
      "17\n",
      "6\n",
      "7\n",
      "5\n",
      "14\n",
      "8\n",
      "7\n",
      "23\n",
      "5\n",
      "3\n",
      "90\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "11\n",
      "7\n",
      "11\n",
      "7\n",
      "18\n",
      "25\n",
      "1\n",
      "16\n",
      "22\n",
      "13\n",
      "1\n",
      "5\n",
      "11\n",
      "30\n",
      "5\n",
      "3\n",
      "10\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for x in x_test_vec:\n",
    "    print(x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vec0 = vectorizer_t.transform(data[data['predict_sold'] == 0]['full_description'].head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "13\n",
      "130\n",
      "81\n",
      "28\n",
      "40\n",
      "13\n",
      "151\n",
      "151\n",
      "8\n",
      "42\n",
      "145\n",
      "31\n",
      "29\n",
      "9\n",
      "6\n",
      "13\n",
      "9\n",
      "9\n",
      "28\n",
      "7\n",
      "15\n",
      "27\n",
      "21\n",
      "14\n",
      "77\n",
      "68\n",
      "80\n",
      "14\n",
      "14\n",
      "16\n",
      "37\n",
      "4\n",
      "43\n",
      "47\n",
      "24\n",
      "16\n",
      "25\n",
      "29\n",
      "26\n",
      "83\n",
      "12\n",
      "94\n",
      "40\n",
      "76\n",
      "12\n",
      "9\n",
      "20\n",
      "25\n",
      "20\n",
      "42\n",
      "42\n",
      "32\n",
      "10\n",
      "33\n",
      "33\n",
      "27\n",
      "20\n",
      "35\n",
      "1\n",
      "31\n",
      "11\n",
      "21\n",
      "12\n",
      "10\n",
      "7\n",
      "34\n",
      "24\n",
      "31\n",
      "31\n",
      "30\n",
      "21\n",
      "8\n",
      "28\n",
      "30\n",
      "25\n",
      "13\n",
      "30\n",
      "75\n",
      "54\n",
      "71\n",
      "31\n",
      "5\n",
      "46\n",
      "9\n",
      "175\n",
      "22\n",
      "13\n",
      "45\n",
      "39\n",
      "49\n",
      "67\n",
      "75\n",
      "65\n",
      "48\n",
      "47\n",
      "29\n",
      "30\n",
      "29\n",
      "13\n",
      "20\n",
      "21\n",
      "24\n",
      "19\n",
      "45\n",
      "60\n",
      "35\n",
      "7\n",
      "9\n",
      "12\n",
      "33\n",
      "43\n",
      "16\n",
      "33\n",
      "19\n",
      "37\n",
      "32\n",
      "30\n",
      "21\n",
      "12\n",
      "53\n",
      "41\n",
      "24\n",
      "38\n",
      "13\n",
      "50\n",
      "15\n",
      "26\n",
      "24\n",
      "52\n",
      "31\n",
      "42\n",
      "35\n",
      "18\n",
      "62\n",
      "23\n",
      "35\n",
      "101\n",
      "12\n",
      "59\n",
      "14\n",
      "6\n",
      "48\n",
      "26\n",
      "30\n",
      "38\n",
      "26\n",
      "32\n",
      "21\n",
      "17\n",
      "48\n",
      "42\n",
      "19\n",
      "45\n",
      "17\n",
      "24\n",
      "56\n",
      "17\n",
      "22\n",
      "21\n",
      "7\n",
      "39\n",
      "17\n",
      "10\n",
      "14\n",
      "23\n",
      "15\n",
      "25\n",
      "26\n",
      "45\n",
      "22\n",
      "28\n",
      "19\n",
      "24\n",
      "15\n",
      "27\n",
      "5\n",
      "28\n",
      "62\n",
      "23\n",
      "15\n",
      "26\n",
      "21\n",
      "10\n",
      "34\n",
      "6\n",
      "45\n",
      "30\n",
      "53\n",
      "56\n",
      "49\n",
      "14\n",
      "3\n",
      "20\n",
      "43\n",
      "7\n",
      "29\n",
      "41\n",
      "34\n",
      "37\n",
      "23\n",
      "22\n",
      "127\n",
      "6\n",
      "3\n",
      "118\n",
      "130\n",
      "116\n",
      "35\n",
      "28\n",
      "21\n",
      "52\n",
      "27\n",
      "9\n",
      "28\n",
      "27\n",
      "13\n",
      "19\n",
      "130\n",
      "13\n",
      "24\n",
      "11\n",
      "12\n",
      "5\n",
      "15\n",
      "21\n",
      "27\n",
      "31\n",
      "9\n",
      "126\n",
      "4\n",
      "47\n",
      "21\n",
      "8\n",
      "37\n",
      "67\n",
      "28\n",
      "12\n",
      "6\n",
      "10\n",
      "15\n",
      "57\n",
      "17\n",
      "8\n",
      "28\n",
      "9\n",
      "26\n",
      "29\n",
      "69\n",
      "9\n",
      "30\n",
      "45\n",
      "14\n",
      "17\n",
      "46\n",
      "71\n",
      "40\n",
      "99\n",
      "47\n",
      "8\n",
      "54\n",
      "57\n",
      "21\n",
      "36\n",
      "55\n",
      "21\n",
      "16\n",
      "24\n",
      "50\n",
      "42\n",
      "56\n",
      "36\n",
      "29\n",
      "10\n",
      "18\n",
      "33\n",
      "23\n",
      "13\n",
      "13\n",
      "18\n",
      "21\n",
      "12\n",
      "9\n",
      "46\n",
      "52\n",
      "5\n",
      "3\n",
      "29\n",
      "5\n",
      "39\n",
      "9\n",
      "20\n",
      "7\n",
      "57\n",
      "13\n",
      "57\n",
      "24\n",
      "12\n",
      "71\n",
      "5\n",
      "47\n",
      "21\n",
      "45\n",
      "98\n",
      "104\n",
      "120\n",
      "67\n",
      "136\n",
      "83\n",
      "92\n",
      "90\n",
      "46\n",
      "58\n",
      "47\n",
      "66\n",
      "48\n",
      "13\n",
      "62\n",
      "3\n",
      "8\n",
      "45\n",
      "52\n",
      "61\n",
      "63\n",
      "64\n",
      "29\n",
      "13\n",
      "9\n",
      "28\n",
      "15\n",
      "30\n",
      "41\n",
      "25\n",
      "16\n",
      "29\n",
      "72\n",
      "46\n",
      "4\n",
      "24\n",
      "51\n",
      "18\n",
      "24\n",
      "116\n",
      "17\n",
      "28\n",
      "17\n",
      "49\n",
      "25\n",
      "9\n",
      "103\n",
      "12\n",
      "93\n",
      "75\n",
      "35\n",
      "12\n",
      "16\n",
      "30\n",
      "25\n",
      "26\n",
      "20\n",
      "34\n",
      "10\n",
      "7\n",
      "6\n",
      "22\n",
      "108\n",
      "66\n",
      "66\n",
      "14\n",
      "43\n",
      "28\n",
      "32\n",
      "72\n",
      "144\n",
      "5\n",
      "18\n",
      "31\n",
      "92\n",
      "75\n",
      "77\n",
      "49\n",
      "30\n",
      "22\n",
      "46\n",
      "14\n",
      "24\n",
      "37\n",
      "23\n",
      "18\n",
      "26\n",
      "51\n",
      "31\n",
      "2\n",
      "38\n",
      "30\n",
      "69\n",
      "70\n",
      "57\n",
      "10\n",
      "52\n",
      "6\n",
      "13\n",
      "7\n",
      "36\n",
      "9\n",
      "53\n",
      "30\n",
      "26\n",
      "10\n",
      "46\n",
      "28\n",
      "111\n",
      "21\n",
      "14\n",
      "48\n",
      "17\n",
      "24\n",
      "9\n",
      "19\n",
      "17\n",
      "26\n",
      "33\n",
      "35\n",
      "18\n",
      "3\n",
      "16\n",
      "18\n",
      "28\n",
      "21\n",
      "17\n",
      "59\n",
      "58\n",
      "72\n",
      "22\n",
      "9\n",
      "25\n",
      "74\n",
      "36\n",
      "11\n",
      "12\n",
      "53\n",
      "46\n",
      "7\n",
      "4\n",
      "5\n",
      "22\n",
      "79\n",
      "28\n",
      "12\n",
      "8\n",
      "44\n",
      "72\n",
      "72\n",
      "40\n",
      "48\n",
      "11\n",
      "11\n",
      "10\n",
      "19\n",
      "50\n",
      "23\n",
      "26\n",
      "16\n",
      "41\n",
      "33\n",
      "27\n",
      "15\n",
      "20\n",
      "27\n",
      "21\n",
      "14\n",
      "21\n",
      "45\n",
      "39\n",
      "110\n",
      "8\n",
      "45\n",
      "11\n",
      "3\n",
      "20\n",
      "37\n",
      "17\n",
      "14\n",
      "27\n",
      "27\n",
      "15\n",
      "5\n",
      "18\n",
      "17\n",
      "14\n",
      "13\n",
      "29\n",
      "18\n",
      "37\n",
      "35\n",
      "73\n",
      "33\n",
      "33\n",
      "94\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "for x in x_test_vec0:\n",
    "    print(x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we extract product state or good price for category???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDK, maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "\n",
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337], [1, 3, 7, 9, 2, 1337, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for i in range(len(new_list) - ngram_range + 1):\n",
    "            for ngram_value in range(2, ngram_range + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "                    new_list.append(token_indice[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Average train sequence length: 238\n",
      "Average test sequence length: 230\n"
     ]
    }
   ],
   "source": [
    "ngram_range = 1\n",
    "max_features = 20000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 5\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\n",
    "print('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32],\n",
       "       [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95],\n",
       "       [1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113],\n",
       "       [1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 15305, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 2, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 18435, 192, 5, 1219, 3890, 19, 2, 217, 4122, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 18665, 594, 7, 5168, 94, 9096, 3987, 15242, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 10161, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 10197, 19, 49, 7, 4, 1885, 13699, 1118, 25, 80, 126, 842, 10, 10, 2, 18223, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 16376, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 13699, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 16376, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 11120, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 11876, 1775, 3353, 12716, 1846, 4, 11286, 7, 154, 5, 4, 518, 53, 13243, 11286, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 18223, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 10359, 9, 242, 4, 91, 1202, 11377, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 18223, 13, 188, 1076, 3222, 19, 4, 13465, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 18223, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 12283, 7, 5991, 5, 94, 40, 25, 238, 60, 2, 4, 15812, 804, 2, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 13713, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574],\n",
       "       [1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 2, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113],\n",
       "       [1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 7982, 1051, 2, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 2, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 15344, 10, 10],\n",
       "       [1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 10626, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 16393, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901],\n",
       "       [1, 4, 14906, 716, 4, 65, 7, 4, 689, 4367, 6308, 2343, 4804, 2, 2, 5270, 2, 2315, 2, 12572, 2, 2, 4, 10993, 628, 7685, 37, 9, 150, 4, 9820, 4069, 11, 2909, 4, 16287, 847, 313, 6, 176, 2, 9, 6202, 138, 9, 4434, 19, 4, 96, 183, 26, 4, 192, 15, 27, 5842, 799, 7101, 2, 588, 84, 11, 4, 3231, 152, 339, 5206, 42, 4869, 2, 6293, 345, 4804, 2, 142, 43, 218, 208, 54, 29, 853, 659, 46, 4, 882, 183, 80, 115, 30, 4, 172, 174, 10, 10, 1001, 398, 1001, 1055, 526, 34, 3717, 2, 5262, 2, 17, 4, 6706, 1094, 871, 64, 85, 22, 2030, 1109, 38, 230, 9, 4, 4324, 2, 251, 5056, 1034, 195, 301, 14, 16, 31, 7, 4, 2, 8, 783, 2, 33, 4, 2945, 103, 465, 16454, 42, 845, 45, 446, 11, 1895, 19, 184, 76, 32, 4, 5310, 207, 110, 13, 197, 4, 14906, 16, 601, 964, 2152, 595, 13, 258, 4, 1730, 66, 338, 55, 5312, 4, 550, 728, 65, 1196, 8, 1839, 61, 1546, 42, 8361, 61, 602, 120, 45, 7304, 6, 320, 786, 99, 196, 11100, 786, 5936, 4, 225, 4, 373, 1009, 33, 4, 130, 63, 69, 72, 1104, 46, 1292, 225, 14, 66, 194, 11871, 1703, 56, 8, 803, 1004, 6, 18763, 155, 11, 4, 14906, 3231, 45, 853, 2029, 8, 30, 6, 117, 430, 19, 6, 8941, 9, 15, 66, 424, 8, 2337, 178, 9, 15, 66, 424, 8, 1465, 178, 9, 15, 66, 142, 15, 9, 424, 8, 28, 178, 662, 44, 12, 17, 4, 130, 898, 1686, 9, 6, 5623, 267, 185, 430, 4, 118, 2, 277, 15, 4, 1188, 100, 216, 56, 19, 4, 357, 114, 10399, 367, 45, 115, 93, 788, 121, 4, 14906, 79, 32, 68, 278, 39, 8, 818, 162, 4165, 237, 600, 7, 98, 306, 8, 157, 549, 628, 11, 6, 12370, 13, 824, 15, 4104, 76, 42, 138, 36, 774, 77, 1059, 159, 150, 4, 229, 497, 8, 1493, 11, 175, 251, 453, 19, 8651, 189, 12, 43, 127, 6, 394, 292, 7, 8253, 4, 107, 8, 4, 2826, 15, 1082, 1251, 9, 906, 42, 1134, 6, 66, 78, 22, 15, 13, 244, 2519, 8, 135, 233, 52, 44, 10, 10, 466, 112, 398, 526, 34, 4, 1572, 4413, 6706, 1094, 225, 57, 599, 133, 225, 6, 227, 7, 541, 4323, 6, 171, 139, 7, 539, 11890, 56, 11, 6, 3231, 21, 164, 25, 426, 81, 33, 344, 624, 19, 6, 4617, 7, 10373, 12958, 6, 5802, 4, 22, 9, 1082, 629, 237, 45, 188, 6, 55, 655, 707, 6371, 956, 225, 1456, 841, 42, 1310, 225, 6, 2493, 1467, 7722, 2828, 21, 4, 14906, 9, 364, 23, 4, 2228, 2407, 225, 24, 76, 133, 18, 4, 189, 2293, 10, 10, 814, 11, 2, 11, 2642, 14, 47, 15, 682, 364, 352, 168, 44, 12, 45, 24, 913, 93, 21, 247, 2441, 4, 116, 34, 35, 1859, 8, 72, 177, 9, 164, 8, 901, 344, 44, 13, 191, 135, 13, 126, 421, 233, 18, 259, 10, 10, 4, 14906, 6847, 4, 14065, 3074, 7, 112, 199, 753, 357, 39, 63, 12, 115, 15222, 763, 8, 15, 35, 3282, 1523, 65, 57, 599, 6, 1916, 277, 1730, 37, 25, 92, 202, 6, 8848, 44, 25, 28, 6, 22, 15, 122, 24, 4171, 72, 33, 32],\n",
       "       [1, 43, 188, 46, 5, 566, 264, 51, 6, 530, 664, 14, 9, 1713, 81, 25, 1135, 46, 7, 6, 20, 750, 11, 141, 4299, 5, 15455, 4441, 102, 28, 413, 38, 120, 5533, 15, 4, 3974, 7, 5369, 142, 371, 318, 5, 955, 1713, 571, 2, 2, 122, 14, 8, 72, 54, 12, 86, 385, 46, 5, 14, 20, 9, 399, 8, 72, 150, 13, 161, 124, 6, 155, 44, 14, 159, 170, 83, 12, 5, 51, 6, 866, 48, 25, 842, 4, 1120, 25, 238, 79, 4, 547, 15, 14, 9, 31, 7, 148, 16126, 102, 44, 35, 480, 3823, 2380, 19, 120, 4, 350, 228, 5, 269, 8, 28, 178, 1314, 2347, 7, 51, 6, 87, 65, 12, 9, 979, 21, 95, 24, 3186, 178, 11, 2, 14, 9, 24, 15, 20, 4, 84, 376, 4, 65, 14, 127, 141, 6, 52, 292, 7, 4751, 175, 561, 7, 68, 3866, 137, 75, 2541, 68, 182, 5, 235, 175, 333, 19, 98, 50, 9, 38, 76, 724, 4, 6750, 15, 166, 285, 36, 140, 143, 38, 76, 53, 3094, 1301, 4, 6991, 16, 82, 6, 87, 3578, 44, 2527, 7612, 5, 800, 4, 3033, 11, 35, 1728, 96, 21, 14, 22, 9, 76, 53, 7, 6, 406, 65, 13, 43, 219, 12, 639, 21, 13, 80, 140, 5, 135, 15, 14, 9, 31, 7, 4, 118, 3672, 13, 28, 126, 110],\n",
       "       [1, 14, 20, 47, 111, 439, 3445, 19, 12, 15, 166, 12, 216, 125, 40, 6, 364, 352, 707, 1187, 39, 294, 11, 22, 396, 13, 28, 8, 202, 12, 1109, 23, 94, 15201, 151, 111, 211, 469, 4, 20, 13, 258, 546, 1104, 7273, 12, 16, 38, 78, 33, 211, 15, 12, 16, 2849, 63, 93, 12, 6, 253, 106, 10, 10, 48, 335, 267, 18, 6, 364, 1242, 1179, 20, 19, 6, 1009, 7, 1987, 189, 5, 6, 8419, 7, 2723, 13209, 95, 1719, 6, 6035, 7, 3912, 7144, 49, 369, 120, 5, 28, 49, 253, 10, 10, 13, 1041, 19, 85, 795, 15, 4, 481, 9, 55, 78, 807, 9, 375, 8, 1167, 8, 794, 76, 7, 4, 58, 5, 4, 816, 9, 243, 7, 43, 50]], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ngram_range > 1:\n",
    "    print('Adding {}-gram features'.format(ngram_range))\n",
    "    # Create set of unique n-gram from the training set.\n",
    "    ngram_set = set()\n",
    "    for input_list in x_train:\n",
    "        for i in range(2, ngram_range + 1):\n",
    "            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "            ngram_set.update(set_of_ngram)\n",
    "\n",
    "    # Dictionary mapping n-gram token to a unique integer.\n",
    "    # Integer values are greater than max_features in order\n",
    "    # to avoid collision with existing features.\n",
    "    start_index = max_features + 1\n",
    "    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "    indice_token = {token_indice[k]: k for k in token_indice}\n",
    "\n",
    "    # max_features is the highest integer that could be found in the dataset.\n",
    "    max_features = np.max(list(indice_token.keys())) + 1\n",
    "\n",
    "    # Augmenting x_train and x_test with n-grams features\n",
    "    x_train = add_ngram(x_train, token_indice, ngram_range)\n",
    "    x_test = add_ngram(x_test, token_indice, ngram_range)\n",
    "    print('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\n",
    "    print('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     1,    14,    22,    16,    43,   530,   973,\n",
       "        1622,  1385,    65,   458,  4468,    66,  3941,     4,   173,\n",
       "          36,   256,     5,    25,   100,    43,   838,   112,    50,\n",
       "         670,     2,     9,    35,   480,   284,     5,   150,     4,\n",
       "         172,   112,   167,     2,   336,   385,    39,     4,   172,\n",
       "        4536,  1111,    17,   546,    38,    13,   447,     4,   192,\n",
       "          50,    16,     6,   147,  2025,    19,    14,    22,     4,\n",
       "        1920,  4613,   469,     4,    22,    71,    87,    12,    16,\n",
       "          43,   530,    38,    76,    15,    13,  1247,     4,    22,\n",
       "          17,   515,    17,    12,    16,   626,    18, 19193,     5,\n",
       "          62,   386,    12,     8,   316,     8,   106,     5,     4,\n",
       "        2223,  5244,    16,   480,    66,  3785,    33,     4,   130,\n",
       "          12,    16,    38,   619,     5,    25,   124,    51,    36,\n",
       "         135,    48,    25,  1415,    33,     6,    22,    12,   215,\n",
       "          28,    77,    52,     5,    14,   407,    16,    82, 10311,\n",
       "           8,     4,   107,   117,  5952,    15,   256,     4,     2,\n",
       "           7,  3766,     5,   723,    36,    71,    43,   530,   476,\n",
       "          26,   400,   317,    46,     7,     4, 12118,  1029,    13,\n",
       "         104,    88,     4,   381,    15,   297,    98,    32,  2071,\n",
       "          56,    26,   141,     6,   194,  7486,    18,     4,   226,\n",
       "          22,    21,   134,   476,    26,   480,     5,   144,    30,\n",
       "        5535,    18,    51,    36,    28,   224,    92,    25,   104,\n",
       "           4,   226,    65,    16,    38,  1334,    88,    12,    16,\n",
       "         283,     5,    16,  4472,   113,   103,    32,    15,    16,\n",
       "        5345,    19,   178,    32], dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 12s 490us/step - loss: 0.6126 - acc: 0.7430 - val_loss: 0.5051 - val_acc: 0.8225\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 12s 480us/step - loss: 0.4060 - acc: 0.8632 - val_loss: 0.3740 - val_acc: 0.8646\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 12s 482us/step - loss: 0.3062 - acc: 0.8934 - val_loss: 0.3220 - val_acc: 0.8782\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 12s 472us/step - loss: 0.2551 - acc: 0.9110 - val_loss: 0.2971 - val_acc: 0.8853\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 12s 477us/step - loss: 0.2207 - acc: 0.9248 - val_loss: 0.2843 - val_acc: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad9ea21a90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting 1\n",
      "115154\n",
      "fitting 2\n",
      "texts to seqs\n",
      "padding\n"
     ]
    }
   ],
   "source": [
    "min_count = 2\n",
    "\n",
    "#docs = create_docs(data[['id','description']])\n",
    "tokenizer = Tokenizer()\n",
    "print('fitting 1')\n",
    "tokenizer.fit_on_texts(data[data['predict_sold'] == 1]['description'])\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "print(num_words)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "print('fitting 2')\n",
    "tokenizer.fit_on_texts(data[data['predict_sold'] == 1]['description'])\n",
    "\n",
    "print('texts to seqs')\n",
    "docs = tokenizer.texts_to_sequences(data[data['predict_sold'] == 1]['description'])\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "print('padding')\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = data[data['predict_sold'] == 1][['id', 'description', 'predict_sold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_data = data[data['predict_sold'] == 0][['id', 'description', 'predict_sold']]\n",
    "temp_train_data_sampled = temp_train_data.sample(frac=0.4, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = TRAIN_DATA.append(temp_train_data_sampled, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4231108"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = shuffle(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting 1\n",
      "115154\n",
      "fitting 2\n",
      "texts to seqs\n",
      "padding\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-466e03d60ba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'padding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/data-ninja/lib/python3.6/site-packages/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_count = 2\n",
    "\n",
    "#docs = create_docs(data[['id','description']])\n",
    "tokenizer = Tokenizer()\n",
    "print('fitting 1')\n",
    "tokenizer.fit_on_texts(TRAIN_DATA[TRAIN_DATA['predict_sold'] == 1]['description'])\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "print(num_words)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "print('fitting 2')\n",
    "tokenizer.fit_on_texts(TRAIN_DATA[TRAIN_DATA['predict_sold'] == 1]['description'])\n",
    "\n",
    "print('texts to seqs')\n",
    "docs = tokenizer.texts_to_sequences(TRAIN_DATA['description'])\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "print('padding')\n",
    "docs = pad_sequences(sequences=docs, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_sequences_and_pad(text_row, max_len=500):\n",
    "    doc = tokenizer.texts_to_sequences(text_row)\n",
    "    return pad_sequences(sequences=doc, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_HEAD = TRAIN_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/data-ninja/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "TRAIN_HEAD['sentimental'] = TRAIN_HEAD['description'].apply(lambda row: transform_to_sequences_and_pad(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = TRAIN_HEAD.head(1)['sentimental'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 146], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data-ninja]",
   "language": "python",
   "name": "conda-env-data-ninja-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
